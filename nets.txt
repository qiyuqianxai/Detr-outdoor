----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 400, 400]           9,408
 FrozenBatchNorm2d-2         [-1, 64, 400, 400]             128
              ReLU-3         [-1, 64, 400, 400]               0
         MaxPool2d-4         [-1, 64, 200, 200]               0
            Conv2d-5         [-1, 64, 200, 200]           4,096
 FrozenBatchNorm2d-6         [-1, 64, 200, 200]             128
              ReLU-7         [-1, 64, 200, 200]               0
            Conv2d-8         [-1, 64, 200, 200]          36,864
 FrozenBatchNorm2d-9         [-1, 64, 200, 200]             128
             ReLU-10         [-1, 64, 200, 200]               0
           Conv2d-11        [-1, 256, 200, 200]          16,384
FrozenBatchNorm2d-12        [-1, 256, 200, 200]             512
           Conv2d-13        [-1, 256, 200, 200]          16,384
FrozenBatchNorm2d-14        [-1, 256, 200, 200]             512
             ReLU-15        [-1, 256, 200, 200]               0
       Bottleneck-16        [-1, 256, 200, 200]               0
           Conv2d-17         [-1, 64, 200, 200]          16,384
FrozenBatchNorm2d-18         [-1, 64, 200, 200]             128
             ReLU-19         [-1, 64, 200, 200]               0
           Conv2d-20         [-1, 64, 200, 200]          36,864
FrozenBatchNorm2d-21         [-1, 64, 200, 200]             128
             ReLU-22         [-1, 64, 200, 200]               0
           Conv2d-23        [-1, 256, 200, 200]          16,384
FrozenBatchNorm2d-24        [-1, 256, 200, 200]             512
             ReLU-25        [-1, 256, 200, 200]               0
       Bottleneck-26        [-1, 256, 200, 200]               0
           Conv2d-27         [-1, 64, 200, 200]          16,384
FrozenBatchNorm2d-28         [-1, 64, 200, 200]             128
             ReLU-29         [-1, 64, 200, 200]               0
           Conv2d-30         [-1, 64, 200, 200]          36,864
FrozenBatchNorm2d-31         [-1, 64, 200, 200]             128
             ReLU-32         [-1, 64, 200, 200]               0
           Conv2d-33        [-1, 256, 200, 200]          16,384
FrozenBatchNorm2d-34        [-1, 256, 200, 200]             512
             ReLU-35        [-1, 256, 200, 200]               0
       Bottleneck-36        [-1, 256, 200, 200]               0
           Conv2d-37        [-1, 128, 200, 200]          32,768
FrozenBatchNorm2d-38        [-1, 128, 200, 200]             256
             ReLU-39        [-1, 128, 200, 200]               0
           Conv2d-40        [-1, 128, 100, 100]         147,456
FrozenBatchNorm2d-41        [-1, 128, 100, 100]             256
             ReLU-42        [-1, 128, 100, 100]               0
           Conv2d-43        [-1, 512, 100, 100]          65,536
FrozenBatchNorm2d-44        [-1, 512, 100, 100]           1,024
           Conv2d-45        [-1, 512, 100, 100]         131,072
FrozenBatchNorm2d-46        [-1, 512, 100, 100]           1,024
             ReLU-47        [-1, 512, 100, 100]               0
       Bottleneck-48        [-1, 512, 100, 100]               0
           Conv2d-49        [-1, 128, 100, 100]          65,536
FrozenBatchNorm2d-50        [-1, 128, 100, 100]             256
             ReLU-51        [-1, 128, 100, 100]               0
           Conv2d-52        [-1, 128, 100, 100]         147,456
FrozenBatchNorm2d-53        [-1, 128, 100, 100]             256
             ReLU-54        [-1, 128, 100, 100]               0
           Conv2d-55        [-1, 512, 100, 100]          65,536
FrozenBatchNorm2d-56        [-1, 512, 100, 100]           1,024
             ReLU-57        [-1, 512, 100, 100]               0
       Bottleneck-58        [-1, 512, 100, 100]               0
           Conv2d-59        [-1, 128, 100, 100]          65,536
FrozenBatchNorm2d-60        [-1, 128, 100, 100]             256
             ReLU-61        [-1, 128, 100, 100]               0
           Conv2d-62        [-1, 128, 100, 100]         147,456
FrozenBatchNorm2d-63        [-1, 128, 100, 100]             256
             ReLU-64        [-1, 128, 100, 100]               0
           Conv2d-65        [-1, 512, 100, 100]          65,536
FrozenBatchNorm2d-66        [-1, 512, 100, 100]           1,024
             ReLU-67        [-1, 512, 100, 100]               0
       Bottleneck-68        [-1, 512, 100, 100]               0
           Conv2d-69        [-1, 128, 100, 100]          65,536
FrozenBatchNorm2d-70        [-1, 128, 100, 100]             256
             ReLU-71        [-1, 128, 100, 100]               0
           Conv2d-72        [-1, 128, 100, 100]         147,456
FrozenBatchNorm2d-73        [-1, 128, 100, 100]             256
             ReLU-74        [-1, 128, 100, 100]               0
           Conv2d-75        [-1, 512, 100, 100]          65,536
FrozenBatchNorm2d-76        [-1, 512, 100, 100]           1,024
             ReLU-77        [-1, 512, 100, 100]               0
       Bottleneck-78        [-1, 512, 100, 100]               0
           Conv2d-79        [-1, 256, 100, 100]         131,072
FrozenBatchNorm2d-80        [-1, 256, 100, 100]             512
             ReLU-81        [-1, 256, 100, 100]               0
           Conv2d-82          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-83          [-1, 256, 50, 50]             512
             ReLU-84          [-1, 256, 50, 50]               0
           Conv2d-85         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-86         [-1, 1024, 50, 50]           2,048
           Conv2d-87         [-1, 1024, 50, 50]         524,288
FrozenBatchNorm2d-88         [-1, 1024, 50, 50]           2,048
             ReLU-89         [-1, 1024, 50, 50]               0
       Bottleneck-90         [-1, 1024, 50, 50]               0
           Conv2d-91          [-1, 256, 50, 50]         262,144
FrozenBatchNorm2d-92          [-1, 256, 50, 50]             512
             ReLU-93          [-1, 256, 50, 50]               0
           Conv2d-94          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-95          [-1, 256, 50, 50]             512
             ReLU-96          [-1, 256, 50, 50]               0
           Conv2d-97         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-98         [-1, 1024, 50, 50]           2,048
             ReLU-99         [-1, 1024, 50, 50]               0
      Bottleneck-100         [-1, 1024, 50, 50]               0
          Conv2d-101          [-1, 256, 50, 50]         262,144
FrozenBatchNorm2d-102          [-1, 256, 50, 50]             512
            ReLU-103          [-1, 256, 50, 50]               0
          Conv2d-104          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-105          [-1, 256, 50, 50]             512
            ReLU-106          [-1, 256, 50, 50]               0
          Conv2d-107         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-108         [-1, 1024, 50, 50]           2,048
            ReLU-109         [-1, 1024, 50, 50]               0
      Bottleneck-110         [-1, 1024, 50, 50]               0
          Conv2d-111          [-1, 256, 50, 50]         262,144
FrozenBatchNorm2d-112          [-1, 256, 50, 50]             512
            ReLU-113          [-1, 256, 50, 50]               0
          Conv2d-114          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-115          [-1, 256, 50, 50]             512
            ReLU-116          [-1, 256, 50, 50]               0
          Conv2d-117         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-118         [-1, 1024, 50, 50]           2,048
            ReLU-119         [-1, 1024, 50, 50]               0
      Bottleneck-120         [-1, 1024, 50, 50]               0
          Conv2d-121          [-1, 256, 50, 50]         262,144
FrozenBatchNorm2d-122          [-1, 256, 50, 50]             512
            ReLU-123          [-1, 256, 50, 50]               0
          Conv2d-124          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-125          [-1, 256, 50, 50]             512
            ReLU-126          [-1, 256, 50, 50]               0
          Conv2d-127         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-128         [-1, 1024, 50, 50]           2,048
            ReLU-129         [-1, 1024, 50, 50]               0
      Bottleneck-130         [-1, 1024, 50, 50]               0
          Conv2d-131          [-1, 256, 50, 50]         262,144
FrozenBatchNorm2d-132          [-1, 256, 50, 50]             512
            ReLU-133          [-1, 256, 50, 50]               0
          Conv2d-134          [-1, 256, 50, 50]         589,824
FrozenBatchNorm2d-135          [-1, 256, 50, 50]             512
            ReLU-136          [-1, 256, 50, 50]               0
          Conv2d-137         [-1, 1024, 50, 50]         262,144
FrozenBatchNorm2d-138         [-1, 1024, 50, 50]           2,048
            ReLU-139         [-1, 1024, 50, 50]               0
      Bottleneck-140         [-1, 1024, 50, 50]               0
          Conv2d-141          [-1, 512, 50, 50]         524,288
FrozenBatchNorm2d-142          [-1, 512, 50, 50]           1,024
            ReLU-143          [-1, 512, 50, 50]               0
          Conv2d-144          [-1, 512, 25, 25]       2,359,296
FrozenBatchNorm2d-145          [-1, 512, 25, 25]           1,024
            ReLU-146          [-1, 512, 25, 25]               0
          Conv2d-147         [-1, 2048, 25, 25]       1,048,576
FrozenBatchNorm2d-148         [-1, 2048, 25, 25]           4,096
          Conv2d-149         [-1, 2048, 25, 25]       2,097,152
FrozenBatchNorm2d-150         [-1, 2048, 25, 25]           4,096
            ReLU-151         [-1, 2048, 25, 25]               0
      Bottleneck-152         [-1, 2048, 25, 25]               0
          Conv2d-153          [-1, 512, 25, 25]       1,048,576
FrozenBatchNorm2d-154          [-1, 512, 25, 25]           1,024
            ReLU-155          [-1, 512, 25, 25]               0
          Conv2d-156          [-1, 512, 25, 25]       2,359,296
FrozenBatchNorm2d-157          [-1, 512, 25, 25]           1,024
            ReLU-158          [-1, 512, 25, 25]               0
          Conv2d-159         [-1, 2048, 25, 25]       1,048,576
FrozenBatchNorm2d-160         [-1, 2048, 25, 25]           4,096
            ReLU-161         [-1, 2048, 25, 25]               0
      Bottleneck-162         [-1, 2048, 25, 25]               0
          Conv2d-163          [-1, 512, 25, 25]       1,048,576
FrozenBatchNorm2d-164          [-1, 512, 25, 25]           1,024
            ReLU-165          [-1, 512, 25, 25]               0
          Conv2d-166          [-1, 512, 25, 25]       2,359,296
FrozenBatchNorm2d-167          [-1, 512, 25, 25]           1,024
            ReLU-168          [-1, 512, 25, 25]               0
          Conv2d-169         [-1, 2048, 25, 25]       1,048,576
FrozenBatchNorm2d-170         [-1, 2048, 25, 25]           4,096
            ReLU-171         [-1, 2048, 25, 25]               0
      Bottleneck-172         [-1, 2048, 25, 25]               0
IntermediateLayerGetter-173         [-1, 2048, 25, 25]               0
        Backbone-174         [-1, 2048, 25, 25]               0
PositionEmbeddingSine-175          [-1, 256, 25, 25]               0
          Conv2d-176          [-1, 256, 25, 25]         524,544
MultiheadAttention-177  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-178               [-1, 2, 256]               0
       LayerNorm-179               [-1, 2, 256]             512
          Linear-180              [-1, 2, 2048]         526,336
         Dropout-181              [-1, 2, 2048]               0
          Linear-182               [-1, 2, 256]         524,544
         Dropout-183               [-1, 2, 256]               0
       LayerNorm-184               [-1, 2, 256]             512
TransformerEncoderLayer-185               [-1, 2, 256]               0
MultiheadAttention-186  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-187               [-1, 2, 256]               0
       LayerNorm-188               [-1, 2, 256]             512
          Linear-189              [-1, 2, 2048]         526,336
         Dropout-190              [-1, 2, 2048]               0
          Linear-191               [-1, 2, 256]         524,544
         Dropout-192               [-1, 2, 256]               0
       LayerNorm-193               [-1, 2, 256]             512
TransformerEncoderLayer-194               [-1, 2, 256]               0
MultiheadAttention-195  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-196               [-1, 2, 256]               0
       LayerNorm-197               [-1, 2, 256]             512
          Linear-198              [-1, 2, 2048]         526,336
         Dropout-199              [-1, 2, 2048]               0
          Linear-200               [-1, 2, 256]         524,544
         Dropout-201               [-1, 2, 256]               0
       LayerNorm-202               [-1, 2, 256]             512
TransformerEncoderLayer-203               [-1, 2, 256]               0
MultiheadAttention-204  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-205               [-1, 2, 256]               0
       LayerNorm-206               [-1, 2, 256]             512
          Linear-207              [-1, 2, 2048]         526,336
         Dropout-208              [-1, 2, 2048]               0
          Linear-209               [-1, 2, 256]         524,544
         Dropout-210               [-1, 2, 256]               0
       LayerNorm-211               [-1, 2, 256]             512
TransformerEncoderLayer-212               [-1, 2, 256]               0
MultiheadAttention-213  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-214               [-1, 2, 256]               0
       LayerNorm-215               [-1, 2, 256]             512
          Linear-216              [-1, 2, 2048]         526,336
         Dropout-217              [-1, 2, 2048]               0
          Linear-218               [-1, 2, 256]         524,544
         Dropout-219               [-1, 2, 256]               0
       LayerNorm-220               [-1, 2, 256]             512
TransformerEncoderLayer-221               [-1, 2, 256]               0
MultiheadAttention-222  [[-1, 2, 256], [-1, 625, 625]]               0
         Dropout-223               [-1, 2, 256]               0
       LayerNorm-224               [-1, 2, 256]             512
          Linear-225              [-1, 2, 2048]         526,336
         Dropout-226              [-1, 2, 2048]               0
          Linear-227               [-1, 2, 256]         524,544
         Dropout-228               [-1, 2, 256]               0
       LayerNorm-229               [-1, 2, 256]             512
TransformerEncoderLayer-230               [-1, 2, 256]               0
TransformerEncoder-231               [-1, 2, 256]               0
MultiheadAttention-232  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-233               [-1, 2, 256]               0
       LayerNorm-234               [-1, 2, 256]             512
MultiheadAttention-235  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-236               [-1, 2, 256]               0
       LayerNorm-237               [-1, 2, 256]             512
          Linear-238              [-1, 2, 2048]         526,336
         Dropout-239              [-1, 2, 2048]               0
          Linear-240               [-1, 2, 256]         524,544
         Dropout-241               [-1, 2, 256]               0
       LayerNorm-242               [-1, 2, 256]             512
TransformerDecoderLayer-243               [-1, 2, 256]               0
       LayerNorm-244               [-1, 2, 256]             512
MultiheadAttention-245  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-246               [-1, 2, 256]               0
       LayerNorm-247               [-1, 2, 256]             512
MultiheadAttention-248  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-249               [-1, 2, 256]               0
       LayerNorm-250               [-1, 2, 256]             512
          Linear-251              [-1, 2, 2048]         526,336
         Dropout-252              [-1, 2, 2048]               0
          Linear-253               [-1, 2, 256]         524,544
         Dropout-254               [-1, 2, 256]               0
       LayerNorm-255               [-1, 2, 256]             512
TransformerDecoderLayer-256               [-1, 2, 256]               0
       LayerNorm-257               [-1, 2, 256]             512
MultiheadAttention-258  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-259               [-1, 2, 256]               0
       LayerNorm-260               [-1, 2, 256]             512
MultiheadAttention-261  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-262               [-1, 2, 256]               0
       LayerNorm-263               [-1, 2, 256]             512
          Linear-264              [-1, 2, 2048]         526,336
         Dropout-265              [-1, 2, 2048]               0
          Linear-266               [-1, 2, 256]         524,544
         Dropout-267               [-1, 2, 256]               0
       LayerNorm-268               [-1, 2, 256]             512
TransformerDecoderLayer-269               [-1, 2, 256]               0
       LayerNorm-270               [-1, 2, 256]             512
MultiheadAttention-271  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-272               [-1, 2, 256]               0
       LayerNorm-273               [-1, 2, 256]             512
MultiheadAttention-274  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-275               [-1, 2, 256]               0
       LayerNorm-276               [-1, 2, 256]             512
          Linear-277              [-1, 2, 2048]         526,336
         Dropout-278              [-1, 2, 2048]               0
          Linear-279               [-1, 2, 256]         524,544
         Dropout-280               [-1, 2, 256]               0
       LayerNorm-281               [-1, 2, 256]             512
TransformerDecoderLayer-282               [-1, 2, 256]               0
       LayerNorm-283               [-1, 2, 256]             512
MultiheadAttention-284  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-285               [-1, 2, 256]               0
       LayerNorm-286               [-1, 2, 256]             512
MultiheadAttention-287  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-288               [-1, 2, 256]               0
       LayerNorm-289               [-1, 2, 256]             512
          Linear-290              [-1, 2, 2048]         526,336
         Dropout-291              [-1, 2, 2048]               0
          Linear-292               [-1, 2, 256]         524,544
         Dropout-293               [-1, 2, 256]               0
       LayerNorm-294               [-1, 2, 256]             512
TransformerDecoderLayer-295               [-1, 2, 256]               0
       LayerNorm-296               [-1, 2, 256]             512
MultiheadAttention-297  [[-1, 2, 256], [-1, 100, 100]]               0
         Dropout-298               [-1, 2, 256]               0
       LayerNorm-299               [-1, 2, 256]             512
MultiheadAttention-300  [[-1, 2, 256], [-1, 100, 625]]               0
         Dropout-301               [-1, 2, 256]               0
       LayerNorm-302               [-1, 2, 256]             512
          Linear-303              [-1, 2, 2048]         526,336
         Dropout-304              [-1, 2, 2048]               0
          Linear-305               [-1, 2, 256]         524,544
         Dropout-306               [-1, 2, 256]               0
       LayerNorm-307               [-1, 2, 256]             512
TransformerDecoderLayer-308               [-1, 2, 256]               0
       LayerNorm-309               [-1, 2, 256]             512
       LayerNorm-310               [-1, 2, 256]             512
TransformerDecoder-311          [-1, 100, 2, 256]               0
     Transformer-312  [[-1, 2, 100, 256], [-1, 256, 25, 25]]               0
          Linear-313           [-1, 2, 100, 92]          23,644
          Linear-314          [-1, 2, 100, 256]          65,792
          Linear-315          [-1, 2, 100, 256]          65,792
          Linear-316            [-1, 2, 100, 4]           1,028
             MLP-317            [-1, 2, 100, 4]               0
================================================================
Total params: 36,818,336
Trainable params: 36,542,816
Non-trainable params: 275,520
----------------------------------------------------------------
Input size (MB): 7.32
Forward/backward pass size (MB): 4139.30
Params size (MB): 140.45
Estimated Total Size (MB): 4287.08
----------------------------------------------------------------
